{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch TextCNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuxjYPIrNqlF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from sklearn import model_selection\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# cross validation and metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anWn41pYYUKC",
        "outputId": "975127fd-bbad-4112-a333-3f6becfa8054"
      },
      "source": [
        "!pip install -U torchtext==0.8.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.8.0 in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CatFQ3jyYWnr",
        "outputId": "39c16ac8-d9fc-413c-8d23-e81d440c3389"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMz0jqI9SWcT"
      },
      "source": [
        "np.random.seed(500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YU18ICNSaun"
      },
      "source": [
        "df1 = pd.read_csv(\"/content/drive/MyDrive/reddit datasets/both_test.csv\")\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/reddit datasets/both_test.csv\")\n",
        "df3 = pd.read_csv(\"/content/drive/MyDrive/reddit datasets/both_val.csv\")\n",
        "df4 = pd.read_csv(\"/content/drive/MyDrive/reddit datasets/schizoaffective.csv\")\n",
        "df5 = pd.read_csv(\"/content/drive/MyDrive/reddit datasets/AlAnon.csv\")\n",
        "df6 = pd.read_csv(\"/content/drive/MyDrive/reddit datasets/BorderlinePDisorder_10 (1).csv\")\n",
        "df7 = pd.read_csv(\"/content/drive/MyDrive/reddit datasets/alcoholicsanonymous.csv\")\n",
        "df8 = pd.read_csv(\"/content/drive/MyDrive/reddit datasets/OCD.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voVhCwnEYpnG"
      },
      "source": [
        "df4.drop(columns=[\"score\",\"url\",\"Unnamed: 0\",\"comms_num\",\"created\",\"ups\",\"downs\"], inplace=True)\n",
        "df5.drop(columns=[\"score\",\"url\",\"Unnamed: 0\",\"comms_num\",\"created\",\"ups\",\"downs\"], inplace=True)\n",
        "df6.drop(columns=[\"score\",\"url\",\"Unnamed: 0\",\"comms_num\",\"created\",\"ups\",\"downs\"], inplace=True)\n",
        "df7.drop(columns=[\"score\",\"url\",\"Unnamed: 0\",\"comms_num\",\"created\",\"ups\",\"downs\"], inplace=True)\n",
        "df8.drop(columns=[\"score\",\"url\",\"Unnamed: 0\",\"comms_num\",\"created\",\"ups\",\"downs\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM02_YjDSbHv"
      },
      "source": [
        "df4 = df4[df4[\"body\"] != \"[deleted]\"]\n",
        "df5 = df5[df5[\"body\"] != \"[deleted]\"]\n",
        "df6 = df6[df6[\"body\"] != \"[deleted]\"]\n",
        "df7 = df7[df7[\"body\"] != \"[deleted]\"]\n",
        "df8 = df8[df8[\"body\"] != \"[deleted]\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCxalksnSbRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda079ba-9cd8-470b-ddf9-fb06cd5392f1"
      },
      "source": [
        "df4[\"class_id\"] = [6]*len(df4)\n",
        "df5[\"class_id\"] = [7]*len(df5)\n",
        "df6[\"class_id\"] = [8]*len(df6)\n",
        "df7[\"class_id\"] = [7]*len(df7)\n",
        "df8[\"class_id\"] = [9]*len(df8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDnIo3ggSbVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab7cf56-a953-4254-d3b1-086090d77d45"
      },
      "source": [
        "df4.dropna(inplace=True)\n",
        "df5.dropna(inplace=True)\n",
        "df6.dropna(inplace=True)\n",
        "df7.dropna(inplace=True)\n",
        "df8.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX4lNX54SbYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f787b74-1afe-452b-c8af-77a7238a5a4c"
      },
      "source": [
        "df4.rename(columns={\"body\":\"post\",\"id\":\"ID\"}, inplace=True)\n",
        "df5.rename(columns={\"body\":\"post\",\"id\":\"ID\"}, inplace=True)\n",
        "df6.rename(columns={\"body\":\"post\",\"id\":\"ID\"}, inplace=True)\n",
        "df7.rename(columns={\"body\":\"post\",\"id\":\"ID\"}, inplace=True)\n",
        "df8.rename(columns={\"body\":\"post\",\"id\":\"ID\"}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvzQSNEiSbbq"
      },
      "source": [
        "frames = [df1, df2, df3, df4, df5, df6, df7, df8]\n",
        "corpus = pd.concat(frames, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "qeyck7HsSbev",
        "outputId": "d8aec447-a24d-4d03-90aa-c225aee580f3"
      },
      "source": [
        "corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>title</th>\n",
              "      <th>post</th>\n",
              "      <th>class_name</th>\n",
              "      <th>class_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b07b978c-7760-4932-85cb-5797b5e74168</td>\n",
              "      <td>basic needs for neurotypicals : food, clothing...</td>\n",
              "      <td>most people able to be productive and function...</td>\n",
              "      <td>adhd</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b2868fd2-e885-400e-b780-446c9581b1f1</td>\n",
              "      <td>\"you're just an iphone in an android world.: d...</td>\n",
              "      <td>i'm 23f and recently quit my job as a features...</td>\n",
              "      <td>adhd</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3191b3b1-d355-41b6-9588-caeb3e169c9b</td>\n",
              "      <td>\"what kind of music do you listen to?\" no answer</td>\n",
              "      <td>i just got finished with an interview and as t...</td>\n",
              "      <td>adhd</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a3d60895-ef7c-4b57-b5be-632c9fd62150</td>\n",
              "      <td>couldn’t help crying while reading a post that...</td>\n",
              "      <td>off course i’ve forgotten what i exactly read....</td>\n",
              "      <td>adhd</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>66fae18e-e744-495f-b7a0-b985543f5052</td>\n",
              "      <td>shout-out to all the parents with adhd childre...</td>\n",
              "      <td>i have six siblings, and at least 4 of us have...</td>\n",
              "      <td>adhd</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12081</th>\n",
              "      <td>qoprjq</td>\n",
              "      <td>Can you have ocd without having depression???</td>\n",
              "      <td>I mean I do feel very sad and worthless becaus...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12082</th>\n",
              "      <td>qor9f9</td>\n",
              "      <td>Hi! I'm an OCD therapist, and I'm new to reddit.</td>\n",
              "      <td>Hi OCD Community! I am a clinical psychologist...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12083</th>\n",
              "      <td>qoslls</td>\n",
              "      <td>Vent: my mom who I still live with tested posi...</td>\n",
              "      <td>My mom tested positive for covid. Despite the ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12084</th>\n",
              "      <td>qotd5d</td>\n",
              "      <td>Do “intrusive memories” count as intrusive tho...</td>\n",
              "      <td>Random anxiety provoking or triggering memorie...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12085</th>\n",
              "      <td>qotrfn</td>\n",
              "      <td>my partner is getting tired of being asked for...</td>\n",
              "      <td>I have many many OCD themes but a big one is m...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12086 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         ID  ... class_id\n",
              "0      b07b978c-7760-4932-85cb-5797b5e74168  ...        0\n",
              "1      b2868fd2-e885-400e-b780-446c9581b1f1  ...        0\n",
              "2      3191b3b1-d355-41b6-9588-caeb3e169c9b  ...        0\n",
              "3      a3d60895-ef7c-4b57-b5be-632c9fd62150  ...        0\n",
              "4      66fae18e-e744-495f-b7a0-b985543f5052  ...        0\n",
              "...                                     ...  ...      ...\n",
              "12081                                qoprjq  ...        9\n",
              "12082                                qor9f9  ...        9\n",
              "12083                                qoslls  ...        9\n",
              "12084                                qotd5d  ...        9\n",
              "12085                                qotrfn  ...        9\n",
              "\n",
              "[12086 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOCrml9sZs7A"
      },
      "source": [
        "corpus[\"text\"] = corpus.title + \" \" + corpus.post"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "sVd7Oz4EZtih",
        "outputId": "3d6ef265-53eb-4cc9-9350-550f44fe053a"
      },
      "source": [
        "corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>title</th>\n",
              "      <th>post</th>\n",
              "      <th>class_name</th>\n",
              "      <th>class_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b07b978c-7760-4932-85cb-5797b5e74168</td>\n",
              "      <td>basic needs for neurotypicals : food, clothing...</td>\n",
              "      <td>most people able to be productive and function...</td>\n",
              "      <td>adhd</td>\n",
              "      <td>0</td>\n",
              "      <td>basic needs for neurotypicals : food, clothing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b2868fd2-e885-400e-b780-446c9581b1f1</td>\n",
              "      <td>\"you're just an iphone in an android world.: d...</td>\n",
              "      <td>i'm 23f and recently quit my job as a features...</td>\n",
              "      <td>adhd</td>\n",
              "      <td>0</td>\n",
              "      <td>\"you're just an iphone in an android world.: d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3191b3b1-d355-41b6-9588-caeb3e169c9b</td>\n",
              "      <td>\"what kind of music do you listen to?\" no answer</td>\n",
              "      <td>i just got finished with an interview and as t...</td>\n",
              "      <td>adhd</td>\n",
              "      <td>0</td>\n",
              "      <td>\"what kind of music do you listen to?\" no answ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a3d60895-ef7c-4b57-b5be-632c9fd62150</td>\n",
              "      <td>couldn’t help crying while reading a post that...</td>\n",
              "      <td>off course i’ve forgotten what i exactly read....</td>\n",
              "      <td>adhd</td>\n",
              "      <td>0</td>\n",
              "      <td>couldn’t help crying while reading a post that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>66fae18e-e744-495f-b7a0-b985543f5052</td>\n",
              "      <td>shout-out to all the parents with adhd childre...</td>\n",
              "      <td>i have six siblings, and at least 4 of us have...</td>\n",
              "      <td>adhd</td>\n",
              "      <td>0</td>\n",
              "      <td>shout-out to all the parents with adhd childre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12081</th>\n",
              "      <td>qoprjq</td>\n",
              "      <td>Can you have ocd without having depression???</td>\n",
              "      <td>I mean I do feel very sad and worthless becaus...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>Can you have ocd without having depression??? ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12082</th>\n",
              "      <td>qor9f9</td>\n",
              "      <td>Hi! I'm an OCD therapist, and I'm new to reddit.</td>\n",
              "      <td>Hi OCD Community! I am a clinical psychologist...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>Hi! I'm an OCD therapist, and I'm new to reddi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12083</th>\n",
              "      <td>qoslls</td>\n",
              "      <td>Vent: my mom who I still live with tested posi...</td>\n",
              "      <td>My mom tested positive for covid. Despite the ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>Vent: my mom who I still live with tested posi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12084</th>\n",
              "      <td>qotd5d</td>\n",
              "      <td>Do “intrusive memories” count as intrusive tho...</td>\n",
              "      <td>Random anxiety provoking or triggering memorie...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>Do “intrusive memories” count as intrusive tho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12085</th>\n",
              "      <td>qotrfn</td>\n",
              "      <td>my partner is getting tired of being asked for...</td>\n",
              "      <td>I have many many OCD themes but a big one is m...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>my partner is getting tired of being asked for...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12086 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         ID  ...                                               text\n",
              "0      b07b978c-7760-4932-85cb-5797b5e74168  ...  basic needs for neurotypicals : food, clothing...\n",
              "1      b2868fd2-e885-400e-b780-446c9581b1f1  ...  \"you're just an iphone in an android world.: d...\n",
              "2      3191b3b1-d355-41b6-9588-caeb3e169c9b  ...  \"what kind of music do you listen to?\" no answ...\n",
              "3      a3d60895-ef7c-4b57-b5be-632c9fd62150  ...  couldn’t help crying while reading a post that...\n",
              "4      66fae18e-e744-495f-b7a0-b985543f5052  ...  shout-out to all the parents with adhd childre...\n",
              "...                                     ...  ...                                                ...\n",
              "12081                                qoprjq  ...  Can you have ocd without having depression??? ...\n",
              "12082                                qor9f9  ...  Hi! I'm an OCD therapist, and I'm new to reddi...\n",
              "12083                                qoslls  ...  Vent: my mom who I still live with tested posi...\n",
              "12084                                qotd5d  ...  Do “intrusive memories” count as intrusive tho...\n",
              "12085                                qotrfn  ...  my partner is getting tired of being asked for...\n",
              "\n",
              "[12086 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4QJY39xdu7i"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vCKcD3BSbiX"
      },
      "source": [
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(corpus['text'], corpus['class_id'], test_size=0.3, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fH84r75SbxV"
      },
      "source": [
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 120000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 750 # max number of words in a question to use\n",
        "batch_size = 512 # how many samples to process at once\n",
        "n_splits = 6 # Number of K-fold Splits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8i6JkHgfhEL"
      },
      "source": [
        "#Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(x_train))\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "# Pad the sentences \n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test= pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MWAWS_8jA_L",
        "outputId": "f0bf0cd5-686e-48bd-b706-b28c69798fe8"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "!ls -lat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-09 16:39:04--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-12-09 16:39:05--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-12-09 16:39:05--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  4.84MB/s    in 2m 40s  \n",
            "\n",
            "2021-12-09 16:41:45 (5.13 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: total 3881136\n",
            "drwxr-xr-x 1 root root       4096 Dec  9 16:39 .\n",
            "drwx------ 6 root root       4096 Dec  9 15:42 drive\n",
            "drwxr-xr-x 1 root root       4096 Dec  9 15:38 ..\n",
            "drwxr-xr-x 1 root root       4096 Dec  3 14:33 sample_data\n",
            "drwxr-xr-x 4 root root       4096 Dec  3 14:33 .config\n",
            "-rw-r--r-- 1 root root  862182613 Oct 25  2015 glove.6B.zip\n",
            "-rw-r--r-- 1 root root  862182613 Oct 25  2015 glove.6B.zip.1\n",
            "-rw-rw-r-- 1 root root 1037962819 Aug 27  2014 glove.6B.300d.txt\n",
            "-rw-rw-r-- 1 root root  171350079 Aug  4  2014 glove.6B.50d.txt\n",
            "-rw-rw-r-- 1 root root  693432828 Aug  4  2014 glove.6B.200d.txt\n",
            "-rw-rw-r-- 1 root root  347116733 Aug  4  2014 glove.6B.100d.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vefiYATffxGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "131a8b2f-e739-4c51-8351-0afb411e48ec"
      },
      "source": [
        "def load_glove(word_index,embed_size):\n",
        "    EMBEDDING_FILE = '../content/glove.6B.'+str(embed_size)+'d.txt'\n",
        "    def get_coefs(word,*arr): \n",
        "      return word, np.asarray(arr, dtype='float32')[:embed_size]\n",
        "\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
        "    all_embs = np.stack(embeddings_index.values())\n",
        "    emb_mean,emb_std = -0.005838499,0.48782197\n",
        "    embed_size_2 = all_embs.shape[1]\n",
        "    nb_words = min(max_features, len(word_index)+1)\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size_2))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features: continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            embedding_vector = embeddings_index.get(word.capitalize())\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "embedding_matrix = load_glove(tokenizer.word_index,embed_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugK259cpgExE",
        "outputId": "53e24fa5-5ba7-4e88-f6f7-908d39067cf3"
      },
      "source": [
        "np.shape(embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30520, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTwUlObT-6ZV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RoN9gN1-wqe"
      },
      "source": [
        "class TextCNN_Classifier(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(TextCNN_Classifier, self).__init__()\n",
        "        #kernel size will be filter _size * embedding size\n",
        "        # we will have 5 filter covering these many words at a time\n",
        "        self.filter_1 = 1 \n",
        "        self.filter_2 = 2\n",
        "        self.filter_3 = 3\n",
        "        self.filter_4 = 4\n",
        "        self.filter_5 = 5\n",
        "        num_filters = 15 # no of output channels\n",
        "        number_classes = 10\n",
        "        self.embedding = nn.Embedding(max_features, embed_size)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        self.conv_1 = nn.Conv2d(1,num_filters,(self.filter_1, embed_size))\n",
        "        self.conv_2 = nn.Conv2d(1,num_filters,(self.filter_2, embed_size))\n",
        "        self.conv_3 = nn.Conv2d(1,num_filters,(self.filter_3, embed_size))\n",
        "        self.conv_4 = nn.Conv2d(1,num_filters,(self.filter_4, embed_size))\n",
        "        self.conv_5 = nn.Conv2d(1,num_filters,(self.filter_5, embed_size))\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc1 = nn.Linear(5*num_filters, number_classes) # number of layers is 5\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  \n",
        "        x =  x.unsqueeze(1)\n",
        "        x1 =  F.max_pool1d( F.relu(self.conv_1(x)).squeeze(3) , F.relu(self.conv_1(x)).squeeze(3).size(2)).squeeze(2)\n",
        "        x2 =  F.max_pool1d( F.relu(self.conv_2(x)).squeeze(3) , F.relu(self.conv_2(x)).squeeze(3).size(2)).squeeze(2)\n",
        "        x3 =  F.max_pool1d( F.relu(self.conv_3(x)).squeeze(3) , F.relu(self.conv_3(x)).squeeze(3).size(2)).squeeze(2)\n",
        "        x4 =  F.max_pool1d( F.relu(self.conv_4(x)).squeeze(3) , F.relu(self.conv_4(x)).squeeze(3).size(2)).squeeze(2)\n",
        "        x5 =  F.max_pool1d( F.relu(self.conv_5(x)).squeeze(3) , F.relu(self.conv_5(x)).squeeze(3).size(2)).squeeze(2)\n",
        "        x = torch.cat((x1,x2,x3,x4,x5),1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x) \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyNmeLEUlKux",
        "outputId": "739c2d75-10f3-4727-cc8c-834137390b65"
      },
      "source": [
        "n_epochs = 8\n",
        "model = TextCNN_Classifier()\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
        "device = torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Load train and test in CUDA Memory\n",
        "x_train_2 = torch.tensor((x_train), dtype=torch.long)\n",
        "y_train_2 = torch.tensor(y_train.values, dtype=torch.long)\n",
        "x_cv = torch.tensor(x_test, dtype=torch.long)\n",
        "y_cv = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create Torch datasets\n",
        "train = torch.utils.data.TensorDataset(x_train_2, y_train_2)\n",
        "valid = torch.utils.data.TensorDataset(x_cv, y_cv)\n",
        "\n",
        "# Create Data Loaders\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # Set model to train configuration\n",
        "    model.train()\n",
        "    avg_loss = 0.  \n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        # Predict/Forward Pass\n",
        "        y_pred = model(x)\n",
        "        # Compute loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        avg_loss += loss.item() / len(train_loader)\n",
        "    \n",
        "    # Set model to validation configuration -Doesn't get trained here\n",
        "    model.eval()        \n",
        "\n",
        "    val_preds = np.zeros((len(x_cv),10))\n",
        "    #y_pred_2 =[]\n",
        "    y_true =[]\n",
        "    preds = []\n",
        "    labels = []\n",
        "    for i, (x, y) in enumerate(valid_loader):\n",
        "      y_pred_2=torch.argmax(model(x), dim = 1).tolist()\n",
        "      y_pred_2 = map(int, y_pred_2)\n",
        "      preds.extend(list(y_pred_2))\n",
        "      labels.extend(y.tolist())\n",
        "    \n",
        "    val_accuracy = (np.sum(np.array(preds) == np.array(labels)))/len(preds)\n",
        "    f1_scorE_sklearn = f1_score(preds,labels,average=\"weighted\")\n",
        "    print(\"f1 score is: \")\n",
        "    print(f1_scorE_sklearn)\n",
        "    print('Epoch {}/{} \\t val_acc={:.4f} \\t f1_score={:.4f}'.format(\n",
        "                epoch + 1, n_epochs, val_accuracy, f1_scorE_sklearn))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score is: \n",
            "0.5798898361924167\n",
            "Epoch 1/8 \t val_acc=0.4239 \t f1_score=0.5799\n",
            "f1 score is: \n",
            "0.6320072819199404\n",
            "Epoch 2/8 \t val_acc=0.5345 \t f1_score=0.6320\n",
            "f1 score is: \n",
            "0.6982476398356667\n",
            "Epoch 3/8 \t val_acc=0.6561 \t f1_score=0.6982\n",
            "f1 score is: \n",
            "0.7402584661117024\n",
            "Epoch 4/8 \t val_acc=0.7151 \t f1_score=0.7403\n",
            "f1 score is: \n",
            "0.7637332075485664\n",
            "Epoch 5/8 \t val_acc=0.7482 \t f1_score=0.7637\n",
            "f1 score is: \n",
            "0.7875953450007533\n",
            "Epoch 6/8 \t val_acc=0.7761 \t f1_score=0.7876\n",
            "f1 score is: \n",
            "0.7958987888205687\n",
            "Epoch 7/8 \t val_acc=0.7893 \t f1_score=0.7959\n",
            "f1 score is: \n",
            "0.8032176691570134\n",
            "Epoch 8/8 \t val_acc=0.7965 \t f1_score=0.8032\n"
          ]
        }
      ]
    }
  ]
}